#!/usr/bin/env python
# -*- coding: utf-8 -*-

import datetime
import os
import time

from selenium import webdriver
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait

# å®šä¹‰æŠ“å–æ•°æ®çš„urlï¼Œæ—¶é—´è·¨åº¦åŠå­˜å‚¨è·¯å¾„ç­‰åˆå§‹å€¼
BASE_URL = 'https://www.haodf.com/sitemap-zx/'
DATE_START = '20080214'
DATE_END = '20080214'
DIR_PATH = './'
TIME_WAIT = 10
TIME_SLEEP = 2
# log ç¼–ç æ–¹å¼
ENCODING_STYLE = 'gb18030'

# chrome æ— çª—æ¨¡å¼
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
browser = webdriver.Chrome(chrome_options=chrome_options)

# æ˜¾å¼ç­‰å¾…
wait = WebDriverWait(browser, TIME_WAIT)


def down_detail_page(file_path, local_time):
    """
    æ„é€ æ—¥æœŸå¾ªç¯ï¼Œè°ƒç”¨creat_date_page_urlå‡½æ•°ï¼Œä¸‹è½½åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µåˆ°æœ¬åœ°
    :param file_path:
    :param local_time:
    :return: 
    """
    # æŠ“å–ç½‘é¡µçš„èµ·æ­¢æ—¶é—´çš„å­—ç¬¦ä¸²å‹æ—¶é—´æ ¼å¼åŒ–ä¸ºæ—¥æœŸå‹
    advisory_date = datetime.datetime.strptime(DATE_START, '%Y%m%d')
    advisory_date_end = datetime.datetime.strptime(DATE_END, '%Y%m%d')
    # éå†å¾…æŠ“å–ç½‘é¡µèµ·æ­¢æ—¶é—´åŒºé—´
    while advisory_date <= advisory_date_end:
        # ä¸‹é¢è°ƒç”¨å‡½æ•°ç”Ÿæˆå…¨éƒ¨æ¯æ—¥æ‰€æœ‰é¡µé¢çš„  URL ï¼Œè§£æå‡ºåŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µçš„ URL
        # è¯¥å‡½æ•°å†…éƒ¨è°ƒç”¨è·å–è¯¦æƒ…é¡µæºç çš„å‡½æ•° get_detail_page
        # =====================
        # é¦–å…ˆè€ƒè™‘ç”Ÿæˆæ—¶é—´æˆ³ï¼Œç„¶åå–å‰åä¸¤æ¬¡çš„å·®ï¼Œå¦‚æœå·®å°äºæŸä¸ªå€¼ï¼Œè¯´æ˜å¯èƒ½å­˜åœ¨æ‹’ç»è®¿é—®ã€
        # ç½‘é€Ÿå·®æˆ–å…¶ä»–æœªçŸ¥é”™è¯¯ï¼ŒæŠ“å–é¡µé¢ä¸æ­£å¸¸ï¼Œä½†ç¨‹åºä»åœ¨æ— æ•ˆè¿è¡Œ
        # =====================
        # try:
        # ç”¨ time.perf_counter()æ–¹æ³•å»å½“å‰çš„ç³»ç»Ÿæ—¶é—´ï¼Œç²¾ç¡®åˆ°ç§’ï¼Œç„¶ååœ¨ create_date_page_url()
        # è¿è¡Œç»“æŸåå†å–ä¸€æ¬¡ç³»ç»Ÿæ—¶é—´ï¼Œç„¶åå–å·®å€¼åˆ¤æ–­æ˜¯å¦å¤§äºæŸä¸ªå€¼ï¼Œå¦‚æœå°äºï¼Œåˆ™åœæ­¢ç¨‹åºå¹¶åé¦ˆä¿¡æ¯
        start_time = time.perf_counter()
        # è°ƒç”¨å‡½æ•°ç”ŸæˆæŸä¸€å¤©çš„æ¯ä¸€é¡µé¡µé¢ urlï¼Œç„¶åè§£æè·å–è¯¥é¡µé¢ä¸­çš„ title å’Œ url
        creat_date_page_url(advisory_date, file_path, local_time)
        # è¾“å‡ºæµ®ç‚¹å‹æ•°æ®
        delta_time = time.perf_counter() - start_time
        # å‡è®¾ç½‘æ–­äº†ï¼Œè‡³å°‘TIME_WAIT æ—¶é—´ï¼›
        # ç»“æŸ IP è¢«å°ï¼Œè‡³å°‘TIME_WAIT()æ—¶é—´
        # è¾ƒçŸ­æ—¶é—´æˆåŠŸå®Œæˆï¼ˆè¯¥é¡µç©ºç™½æ—  titleï¼‰ï¼š è‡³å°‘ TIME_SLEEP æ—¶é—´
        # æ‰€ä»¥è®¾ç½®å®ŒæˆæŸå¤©æŠ“å–å°äºå¤šå°‘æ—¶é—´æˆ–å¤§äºå¤šå°‘æ—¶é—´æ„ä¹‰ä¸å¤§ï¼Œå¯ä»¥å°†æ—¶å·®æ‰“å°å‡ºæ¥ï¼Œäººæ¥åˆ¤æ–­æ‰‹å·¥ç»ˆæ­¢ç¨‹åº
        # æš‚æ—¶ä¸æ¸…æ¥š browser.get()ä¼šä¸ä¼šè§¦å‘å¼‚å¸¸
        # if delta_time < float()
        # æœ¬æ¥åœ¨ä¸€è¡Œï¼Œdelta_time æœ‰ warning
        print(advisory_date.strftime('%Y-%m-%d'), ' æ—¥çš„é¡µé¢ç”¨æ—¶  ', end='')
        print(delta_time, end='')
        print('  ç§’è§£æå¹¶æŠ“å–å®Œæ¯•')
        advisory_date += datetime.timedelta(days=1)  # æ—¥æœŸæ¨è¿›ä¸€å¤©ï¼Œè”ç³»ä¸‹æ–‡ä¸ç”¨åŠ  time.sleep
        # except Exception:
    else:
        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), ' ç¨‹åºé¡ºåˆ©è¿è¡Œç»“æŸ!')


def creat_date_page_url(advisory_date, file_path, local_time):
    """
    æ ¹æ®ä¼ å…¥çš„æ—¥æœŸå‚æ•°ï¼Œç”Ÿæˆè¯¥æ—¥æ‰€æœ‰é¡µé¢çš„ URL
    ç„¶åè§£æè¯¥é¡µé¢è·å–åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µ URLï¼Œç„¶åè°ƒç”¨ get_detail_page ä¿å­˜è¯¦æƒ…é¡µ
    :param local_time:
    :param file_path:
    :param advisory_date:
    :return:
    """
    for date_page in range(1, 1000):
        date_page_url = BASE_URL + advisory_date.strftime('%Y%m%d') + '_' + str(date_page) + '/'
        # æ‰“å°çŠ¶æ€
        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), ' å¼€å§‹å°è¯•æŠ“å– ', advisory_date.strftime('%Y-%m-%d'),
              ' æ—¥ç¬¬ ', str(date_page), ' é¡µé—®è¯Šè®°å½•')
        try:
            browser.get(date_page_url)  # è·å–å« title å’Œdetail page çš„é¡µé¢
            # é¡µé¢æ˜¯å¦åŠ è½½æˆåŠŸ
            wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class="map_all"]')))
            try:
                # æŸ¥æ‰¾é¡µé¢class nameä¸º'hh'çš„èŠ‚ç‚¹ã€‚è¿™é‡Œä¹Ÿå¯ä»¥ç”¨ try except åš
                # åˆ¤æ–­å¦‚æœæœ‰ hh å­˜åœ¨ï¼Œå¯¹è¯è¯¦æƒ…é¡µ title å’Œ url ä¸€å®šå­˜åœ¨ï¼Œè‡³å°‘ä¸º1ä¸ª
                browser.find_element_by_xpath('//li[@class="hh"]')
                # å’Œ html.xpath è·å– text()ä¸åŒã€‚ç”¨ elements
                item = browser.find_elements_by_xpath('//li/a')
                # ç”Ÿæˆæœ€åç½‘é¡µæ–‡ä»¶åç§°å‰ç¼€
                pre_file_name = advisory_date.strftime('%Y%m%d') + '_' + str(date_page) + '_'
                for i in range(len(item)):
                    # æ‰“å°çŠ¶æ€
                    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), advisory_date.strftime('%Y-%m-%d'),
                          ' æ—¥ç¬¬ ', str(date_page), ' é¡µå…±æœ‰ ', str(len(item)), ' æ¡é—®è¯Šè®°å½•ï¼Œæ­£åœ¨æŠ“å–ç¬¬ ', str(i+1), ' æ¡')
                    # è€ƒè™‘å°†å…¨éƒ¨å°† item_title å’Œ item_urlå­˜å…¥ TXT æ–‡æœ¬
                    # è®°å½•æ‰€æœ‰æˆåŠŸåŠ è½½çš„æŸæ—¥æŸé¡µé¢ä¸­æ‰€æœ‰çš„ title å’Œ urlï¼ŒåŒ…å«å¯èƒ½å°†æ²¡æœ‰æˆåŠŸä¿å­˜è‡³æœ¬åœ°çš„
                    record_title_url_filename = 'TitleandUrl' + DATE_START + DATE_END + local_time
                    with open(file_path + 'log/' + record_title_url_filename + '.txt', 'a', encoding=ENCODING_STYLE) \
                            as record_title_url:
                        record_title_url.write(item[i].get_attribute('href') + '\t' + item[i].text + '\n')
                    # è°ƒç”¨å‡½æ•°è·å–æŸä¸€æ—¥æŸä¸€é¡µä¸Šæ‰€æœ‰åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µ URL å¯¹åº”çš„é¡µé¢å¹¶å­˜å…¥æœ¬åœ°
                    get_detail_page(item[i].get_attribute('href'), pre_file_name, file_path, local_time)
                    # ä»¥ä¸‹éœ€è¦é‡æ–°åŠ è½½ï¼Œä¸ç„¶ä¸‹ä¸€æ¬¡å¾ªç¯å°±ä¼šè§£æget_detail_pageä¸­ get çš„ç½‘é¡µ
                    # å°† item çš„ href å’Œ text å–å‡ºæ¥å­˜å…¥ä¸­é—´é‡ï¼Œæ•°æ®åº“ç­‰å¯ä¸ç”¨é‡è½½å…¥ï¼Œå½“å‰è®¿é—®è¿‡äºé¢‘ç¹
                    browser.get(date_page_url)
                    item = browser.find_elements_by_xpath('//li/a')
                # è®°å½•å«æœ‰ åŒ»æ‚£å¯¹è¯ title å’Œ urlçš„ date_page_url
                normal_date_page_url = 'NormalDatePageUrl' + DATE_START + DATE_END + local_time
                with open(file_path + 'log/' + normal_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                        as normal_date_page:
                    normal_date_page.write(date_page_url + '\n')
                # æå‡é€Ÿåº¦ï¼Œæ³¨é‡Šäº†å¾ªç¯ä¸­çš„ sleep 2018-08-14 2140
                time.sleep(TIME_SLEEP)
            except NoSuchElementException:
                # è®°å½•è¯¥æ—¥æ— è®°å½•ï¼ˆé¦–é¡µæ—  titleï¼Œurlï¼‰æˆ–è¯¥æ—¥æœ‰è®°å½•çš„æœ€åä¸€é¡µçš„åä¸€é¡µçš„ url
                print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), advisory_date.strftime('%Y-%m-%d'),
                      ' æ—¥åªæœ‰ ', str(date_page-1), ' é¡µé—®è¯Šè®°å½•ï¼Œå…¨éƒ¨æŠ“å–å®Œæ¯•')
                empty_date_page_url = 'EmptyDatePageUrl' + DATE_START + DATE_END + local_time
                with open(file_path + 'log/' + empty_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                        as empty_date_page:
                    empty_date_page.write(date_page_url + '\n')
                # é˜²æ­¢é¢‘ç¹è®¿é—®
                time.sleep(TIME_SLEEP)
                # é‡åˆ°æŸæ—¥æŸé¡µæ²¡æœ‰ title å’Œ urlï¼Œå³ç©ºç™½ï¼Œç»“æŸé¡µç å¾ªç¯ï¼Œç­‰å¾…å¼€å§‹ä¸‹ä¸€æ—¥
                break
        except TimeoutException:
            # è€ƒè™‘ IP è¢«å°
            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), date_page_url, ' åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè´¨é‡ï¼ŒIPï¼')
            # æ‰“å° date_page_url æ²¡æœ‰åŠ è½½æˆåŠŸçš„æƒ…å†µï¼Œè®°å½• url
            record_bug_date_page_url = 'BugDatePageUrl' + DATE_START + DATE_END + local_time
            with open(file_path + 'log/' + record_bug_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                    as record_bug_date_page:
                record_bug_date_page.write(date_page_url + '\n')
            # ç»“æŸå¾ªç¯ï¼Œå¼€å§‹è¯·æ±‚ä¸‹ä¸€æ—¥çš„ç¬¬ä¸€é¡µ
            break


def get_detail_page(detail_page_url, pre_file_name, file_path, local_time):
    """
    è·å– æŸä¸€é¡µä¸­æ‰€æœ‰ title å’Œ urlå¯¹åº”çš„åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°
    æœ¬æ¥å‡½æ•°æœ‰ä¸€ä¸ªå¾ªç¯ï¼Œä¼ å…¥çš„æ˜¯ itermï¼Œå½“æ—¶ä¸Šä¸€ä¸ªå‡½æ•°çš„ iterm å’Œ browser.get æ²¡æœ‰åœ¨å¾ªç¯ä¸­ï¼Œå¼•èµ·é‡çš„å˜åŒ–ï¼Œæ€»æ˜¯æŠ¥é”™
    äºæ˜¯æˆ‘å°†æœ¬å‡½æ•°æ”¹ä¸ºå•url è°ƒç”¨ï¼Œåœ¨ä¸Šä¸€ä¸ªå‡½æ•°ä¸­åŠ å…¥äº† iterm å’Œ browse.get çš„é‡è½½å…¥
    :param detail_page_url:
    :param pre_file_name:
    :param file_path:
    :param local_time:
    :return:
    """
    try:
        # æ³¨æ„ href å€¼çš„'//'é—®é¢˜ï¼Œæš‚æœªå¤„ç†ï¼Œå¯è€ƒè™‘ç”¨ xpath æŸ¥æ‰¾åï¼Œç”¨.get_attributeçš„æ–¹æ³•è·å– url
        browser.get(detail_page_url)
        # ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹åŠ è½½å‡ºæ¥
        wait.until(EC.presence_of_all_elements_located)
        # ä¿å­˜ç½‘é¡µæºç ä¸º HTML æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œæ³¨æ„ç¼–ç é—®é¢˜
        elements = browser.find_element_by_xpath('//*')  # å–æºç ä¸­æ‰€æœ‰çš„èŠ‚ç‚¹,elements æ²¡æœ‰sæ²¡é—®é¢˜
        source_code = elements.get_attribute('outerHTML')
        # HTML å‘½åå½¢å¦‚20180322_1_xxx.htm,ä»¥ä¸‹ç”¨åˆ‡ç‰‡çš„æ–¹æ³•è·å–æ²¡æœ‰'/'çš„éƒ¨åˆ†ï¼Œä¸ç„¶ä¼šè¢«è®¤ä¸ºæ˜¯è·¯å¾„
        # åˆ‡ç‰‡ä¹Ÿå¯ä»¥ç”¨ detail_page_url.split('/')[-1]
        # file_name = pre_file_name + detail_page_url.split('/')[-1]
        file_name = pre_file_name + detail_page_url[28:]
        # å‘½åè®°å½•æ‰€æœ‰æˆåŠŸä¿å­˜è‡³æœ¬åœ°çš„ç½‘é¡µçš„åç§°
        record_filename_name = 'NameofSavedPages' + DATE_START + DATE_END + local_time
        # ä¿å­˜ç½‘é¡µæºç åˆ°æœ¬åœ°ï¼Œ file_name è‡ªå¸¦'.htm' åç¼€ï¼Œé‡‡ç”¨å’Œç½‘é¡µç›¸åŒçš„ gbk ç¼–ç 
        with open(file_path + file_name, 'w', encoding='gbk') as file:
            file.write(source_code)
        # ä¿å­˜æˆåŠŸä¸‹è½½çš„ç½‘é¡µçš„åç§°åˆ°'NameofSavedPages'(æ ¹ç›®å½•)æ–‡ä»¶ä¸­ï¼Œè¿™é‡Œæš‚æ—¶ä¸åŠ å¯¹åº” title
        with open(file_path + 'log/' + record_filename_name + '.txt', 'a', encoding=ENCODING_STYLE) as record_filename:
            record_filename.write(file_name + '\n')
        # æŠ“å–æ¯ä¸ªé¡µé¢åç­‰å€™ä¸€ä¸‹ï¼Œé˜²æ­¢è¿‡å¿«è¢«å±è”½
        # 2018-08-14 2140
        # time.sleep(TIME_SLEEP)
    except Exception:
        print(detail_page_url, ' æœªæŠ“å–æˆåŠŸ!')
        # ä¸ºè®°å½•æ²¡æœ‰æˆåŠŸä¿å­˜çš„ HTML çš„ URL çš„ TXT æ–‡ä»¶å‘½å
        record_errfilename_name = 'NameofUnsavedPages' + DATE_START + DATE_END + local_time
        with open(file_path + 'log/' + record_errfilename_name + '.txt', 'a', encoding=ENCODING_STYLE) \
                as record_errfilename:
            record_errfilename.write(pre_file_name + '_' + detail_page_url + '\n')
        # 2018-08-14 2140
        # time.sleep(TIME_SLEEP)
        # browser.close()


def make_dir():
    """
    ç”Ÿæˆä»¥ç½‘é¡µèµ·æ­¢æ—¶é—´å‘½åçš„æ–‡ä»¶å¤¹ï¼Œå¹¶è¿”å›è·¯å¾„ file_path
    :return: file_path
    """
    # å®šä¹‰å­˜å‚¨ HTML æ–‡ä»¶çš„è·¯å¾„ä¸ºåˆå§‹è·¯å¾„ä¸‹èµ·æ­¢æ—¶é—´å‘½åçš„æ–‡ä»¶å¤¹
    file_path = DIR_PATH + DATE_START + '_' + DATE_END + '/'
    # ç”Ÿæˆ TXT æ—¥å¿—å­˜å‚¨è·¯å¾„
    log_path = file_path + 'log/'
    exists = os.path.exists(log_path)
    if not exists:
        os.makedirs(log_path)
        return file_path  # è¿”å›ä¸¤ä¸ªå‚æ•°éº»çƒ¦
    else:
        return file_path


def main():
    """
    ç”Ÿæˆfile_path å’Œlocal_time ä¾›æ•´ä¸ªç¨‹åºä½¿ç”¨
    :return:
    """
    # è€ƒè™‘ try ä¸€ä¸ªå¯¹å¸¸é‡çš„æ£€æŸ¥ï¼Œå¦‚ DATE_START ä¸€å®šåœ¨ DATE_ENG å‰é¢
    local_time = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    # å¯ä»¥è€ƒè™‘ç»™æ–‡ä»¶å¤¹åç§°ä¹Ÿæ¥ä¸€ä¸ª local_time æ ‡è¯†
    # ========================================================
    # å½“å‰è·¯å¾„è®¾ç½®è¦æ±‚ï¼Œå¦‚æœç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼Œéœ€è¦äººå·¥åˆ é™¤ç³»åˆ— log æ–‡ä»¶
    # ========================================================
    file_path = make_dir()
    try:
        down_detail_page(file_path, local_time)  # ä¸‹è½½åŒ»æ‚£å¯¹è¯çš„è¯¦æƒ…é¡µ
        print('ğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸº  ä» ', DATE_START, ' åˆ° ', DATE_END, ' æœŸé—´çš„ç½‘é¡µå·²å…¨éƒ¨å­˜å…¥ ', file_path)  # æç¤ºå®Œæˆ
    except Exception:
        print('ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°  ä» ', DATE_START, ' åˆ° ', DATE_END, ' æœŸé—´çš„ç½‘é¡µè·å–å¤±è´¥!')
    browser.close()


if __name__ == '__main__':
    main()
